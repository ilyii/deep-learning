{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification\n",
    "\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 5 * 5, 4096),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "savepath = \"./output\"\n",
    "os.makedirs(savepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, device, model, optimizer, criterion, trainloader, savepath):\n",
    "    times = []\n",
    "    for epoch in range(num_epochs): \n",
    "        s_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        trainbar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f\"[TRAIN] Epoch {epoch+1}/{num_epochs}\")\n",
    "        for i, data in trainbar:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = torch.mean((outputs.argmax(1) == labels).float())            \n",
    "\n",
    "            writer.add_scalars(f'{device}/train', {'loss': loss, 'acc': acc}, epoch * len(trainloader) + i)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            trainbar.set_postfix(loss=running_loss/(i+1), acc=acc.item())\n",
    "        times.append(time.time()-s_time)\n",
    "        print(f\"{(epoch+1)/num_epochs*100:.2f}% - Loss: {running_loss/len(trainloader):.4f}\", end=\"\\r\", flush=True)\n",
    "\n",
    "    print(f\"Training took {sum(times):.2f}s in total ({sum(times)/num_epochs:.2f}s per epoch)\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(savepath, f\"ckpt_{num_epochs}_{device}.pt\"))\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/10: 100%|██████████| 782/782 [01:56<00:00,  6.71it/s, acc=0.125, loss=2.3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.00% - Loss: 2.3007\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 2/10: 100%|██████████| 782/782 [02:05<00:00,  6.22it/s, acc=0.188, loss=2.22] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.00% - Loss: 2.2227\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 3/10: 100%|██████████| 782/782 [00:40<00:00, 19.22it/s, acc=0.312, loss=1.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.00% - Loss: 1.9510\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 4/10: 100%|██████████| 782/782 [00:41<00:00, 18.84it/s, acc=0.375, loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.00% - Loss: 1.7592\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 5/10: 100%|██████████| 782/782 [01:16<00:00, 10.21it/s, acc=0.5, loss=1.63]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00% - Loss: 1.6290\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 6/10: 100%|██████████| 782/782 [00:43<00:00, 17.95it/s, acc=0.375, loss=1.54]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.00% - Loss: 1.5361\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 7/10: 100%|██████████| 782/782 [00:38<00:00, 20.52it/s, acc=0.5, loss=1.46]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% - Loss: 1.4563\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 8/10: 100%|██████████| 782/782 [00:38<00:00, 20.06it/s, acc=0.312, loss=1.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.00% - Loss: 1.3842\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 9/10: 100%|██████████| 782/782 [01:40<00:00,  7.77it/s, acc=0.625, loss=1.32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.00% - Loss: 1.3153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 10/10: 100%|██████████| 782/782 [02:09<00:00,  6.03it/s, acc=0.562, loss=1.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 752.06s in total (75.21s per epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "cpu_times = train(num_epochs, device, model, optimizer, criterion, trainloader, savepath) #399.06s - 39.91s per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/10: 100%|██████████| 782/782 [00:23<00:00, 33.27it/s, acc=0.188, loss=2.3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.00% - Loss: 2.3010\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 2/10: 100%|██████████| 782/782 [00:18<00:00, 43.43it/s, acc=0.438, loss=2.21] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.00% - Loss: 2.2117\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 3/10: 100%|██████████| 782/782 [00:17<00:00, 43.84it/s, acc=0.438, loss=1.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.00% - Loss: 1.9553\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 4/10: 100%|██████████| 782/782 [00:17<00:00, 44.08it/s, acc=0.375, loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.00% - Loss: 1.7764\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 5/10: 100%|██████████| 782/782 [00:17<00:00, 43.67it/s, acc=0.438, loss=1.66]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00% - Loss: 1.6566\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 6/10: 100%|██████████| 782/782 [00:18<00:00, 43.32it/s, acc=0.438, loss=1.54]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.00% - Loss: 1.5418\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 7/10: 100%|██████████| 782/782 [00:17<00:00, 43.83it/s, acc=0.625, loss=1.44]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% - Loss: 1.4355\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 8/10: 100%|██████████| 782/782 [00:18<00:00, 43.02it/s, acc=0.562, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.00% - Loss: 1.3503\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 9/10: 100%|██████████| 782/782 [00:17<00:00, 44.02it/s, acc=0.625, loss=1.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.00% - Loss: 1.2872\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 10/10: 100%|██████████| 782/782 [00:19<00:00, 39.94it/s, acc=0.75, loss=1.22] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% - Loss: 1.2176\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 186.47s in total (18.65s per epoch)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device=\"cuda\"\n",
    "model.to(device)\n",
    "gpu_times = train(num_epochs, device, model, optimizer, criterion, trainloader, savepath) # 39.91s - 3.99s per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 157/157 [00:23<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "K = 3 # Top-K prediction\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "metrics = {classname: {'top1_pred': 0, \n",
    "                    'topk_pred': 0, \n",
    "                    'total_pred': 0} \n",
    "                    for classname in classes}\n",
    "\n",
    "wrong_samples = list[Tuple]()\n",
    "# Load model\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(os.path.join(savepath, f\"ckpt_{num_epochs}_{device}.pt\")))\n",
    "model.eval().to(device)\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(testloader), total=len(testloader), desc=\"[TEST]\"):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.topk(outputs, k=K, dim=1)  # Get top-K prediction\n",
    "\n",
    "        total = labels.size(0)\n",
    "        top1 = torch.sum(labels.eq(predictions[:, 0])).item()        \n",
    "        topk = torch.any(labels.unsqueeze(1).eq(predictions), dim=1).sum().item()\n",
    "\n",
    "        metrics[classes[labels[0]]]['top1_pred'] += top1\n",
    "        metrics[classes[labels[0]]]['topk_pred'] += topk\n",
    "        metrics[classes[labels[0]]]['total_pred'] += total\n",
    "        \n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label not in prediction:\n",
    "                wrong_samples.append((images[label], label, prediction))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Top-1 Accuracy: 56.79%\n",
      "Overall Top-3 Accuracy: 85.21%\n",
      "Class plane - Top-1 Accuracy: 55.68% - Top-3 Accuracy: 86.36%\n",
      "Class car - Top-1 Accuracy: 58.82% - Top-3 Accuracy: 86.05%\n",
      "Class bird - Top-1 Accuracy: 58.92% - Top-3 Accuracy: 85.20%\n",
      "Class cat - Top-1 Accuracy: 55.06% - Top-3 Accuracy: 84.28%\n",
      "Class deer - Top-1 Accuracy: 59.49% - Top-3 Accuracy: 86.72%\n",
      "Class dog - Top-1 Accuracy: 54.78% - Top-3 Accuracy: 84.47%\n",
      "Class frog - Top-1 Accuracy: 59.06% - Top-3 Accuracy: 86.56%\n",
      "Class horse - Top-1 Accuracy: 53.84% - Top-3 Accuracy: 85.20%\n",
      "Class ship - Top-1 Accuracy: 56.33% - Top-3 Accuracy: 83.88%\n",
      "Class truck - Top-1 Accuracy: 56.86% - Top-3 Accuracy: 84.99%\n"
     ]
    }
   ],
   "source": [
    "# print overall accuracy\n",
    "overall_top1 = sum([metrics[classname]['top1_pred'] for classname in classes]) / sum([metrics[classname]['total_pred'] for classname in classes])\n",
    "print(f\"Overall Top-1 Accuracy: {overall_top1*100:.2f}%\")\n",
    "\n",
    "overall_topk = sum([metrics[classname]['topk_pred'] for classname in classes]) / sum([metrics[classname]['total_pred'] for classname in classes])\n",
    "print(f\"Overall Top-{K} Accuracy: {overall_topk*100:.2f}%\")\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname in classes:\n",
    "    top1 = metrics[classname]['top1_pred'] / metrics[classname]['total_pred']\n",
    "    topk = metrics[classname]['topk_pred'] / metrics[classname]['total_pred']\n",
    "    print(f\"Class {classname} - Top-1 Accuracy: {top1*100:.2f}% - Top-{K} Accuracy: {topk*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong predictions\n",
    "import random\n",
    "for wpred in random.sample(wrong_samples, 5):\n",
    "    writer.add_image(f\"Predicted: {classes[wpred[2][0]]} - Actual: {classes[wpred[1]]}\", wpred[0], dataformats=\"CHW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-270a42ab9baee6eb\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-270a42ab9baee6eb\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
